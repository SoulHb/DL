{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12joErSe-y8STB4SfCmFRRfdVm2ao2JJz",
      "authorship_tag": "ABX9TyM/CQTC4W8ZZb6I1nTscWkC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolutionLr/DL/blob/main/Coffee_Beans_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary modules \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models import resnet34\n",
        "from coffee_beans_dataset import Coffee_Beans\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import torchvision\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "#Create model\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.resnet = resnet34(pretrained=True)\n",
        "        for param in self.resnet.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.resnet.fc = nn.Sequential(nn.Linear(512, 4))\n",
        "\n",
        "    def forward(self, x):\n",
        "        pred = self.resnet(x)\n",
        "        return pred\n",
        "\n",
        "\n",
        "def show_predict(model, loader):\n",
        "    batch = next(iter(loader))\n",
        "    images, _ = batch\n",
        "    images = images.to(device)\n",
        "    pred = model(images)\n",
        "    grid = torchvision.utils.make_grid(images[0:6].cpu(), nrow=3)\n",
        "    plt.figure(figsize=(11, 11))\n",
        "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "    print(pred[0:6].argmax(1))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "#Load data\n",
        "root_dir = '/content/drive/MyDrive/DL_1/coffee_beans_classifier/Coffee'\n",
        "csv_file = '/content/drive/MyDrive/DL_1/coffee_beans_classifier/Coffee/Coffee Bean.csv'\n",
        "coffee_beans_dataset = Coffee_Beans(root_dir, csv_file, transform=transforms.ToTensor())\n",
        "train_loader, test_loader = coffee_beans_dataset.train_test_loader()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Resnet()\n",
        "model.to(device)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epoch = 3\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "#Create train and test loops\n",
        "def train_loop(train_loader, loss, optimizer, model):\n",
        "    size_dataset = len(train_loader.dataset)\n",
        "    model.train()\n",
        "    for X, y in train_loader:\n",
        "        correct = 0\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        y = torch.nn.functional.one_hot(y)\n",
        "        pred = model(X)\n",
        "        L = loss(pred, y.argmax(1))\n",
        "        optimizer.zero_grad()\n",
        "        L.backward()\n",
        "        optimizer.step()\n",
        "        correct = (pred.argmax(1) == y.argmax(1)).float().sum()\n",
        "        accuracy = (correct / len(y)) * 100\n",
        "        print(f\"train_loss: {L.item()}, accuracy/batch: {accuracy}\")\n",
        "\n",
        "\n",
        "def test_loop(test_loader, loss, model):\n",
        "    model.eval()\n",
        "    size_dataset = len(test_loader.dataset)\n",
        "    correct, test_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y = torch.nn.functional.one_hot(y)\n",
        "            y = y.argmax(1)\n",
        "            pred = model(X)\n",
        "            test_loss += loss(pred, y).item() * X.shape[0]\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        test_loss = (test_loss / size_dataset)\n",
        "        accuracy = (correct / size_dataset) * 100\n",
        "        print(f\"test_loss: {test_loss}, accuracy/epoch: {accuracy}\")\n",
        "\n",
        "\n",
        "for i in range(epoch):\n",
        "    train_loop(train_loader, loss, optimizer, model)\n",
        "    test_loop(test_loader, loss, model)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/DL_1/coffee_beans_classifier/ResNet.py')\n",
        "\n",
        "# show some predicted values\n",
        "show_predict(model, test_loader)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RGMhTuiHzumB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}